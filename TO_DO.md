ğŸ“º The best Stanford, CMU, and MIT courses for AI (with YouTube playlists)

- With a multitude of AI courses available online, coming up with an study plan for AI can easily lead to decision fatigue.
- I often get asked about which courses have been useful to me to build a foundation in AI. Hereâ€™s my list of courses along with their respective YouTube playlists.
- Check out my watch list with all of the below pointers (and a much larger list of such resources and more): https://aman.ai/watch

ğŸ“š Stanford University
ğŸ”¹ CS221 - Artificial Intelligence: Principles and Techniques by Percy Liang and Dorsa Sadigh: https://lnkd.in/grECwbD4
ğŸ”¹ CS229 - Machine Learning by Andrew Ng: https://lnkd.in/gY8a2yZN
ğŸ”¹ CS230 - Deep Learning by Andrew Ng: https://lnkd.in/gTk-gKPm
ğŸ”¹ CS231n - Convolutional Neural Networks for Visual Recognition by Fei-Fei Li and Andrej Karpathy: https://lnkd.in/gGUMZH_G
ğŸ”¹ CS224n - Natural Language Processing with Deep Learning by Christopher Manning: https://lnkd.in/giWDZGVX
ğŸ”¹ CS224w - Machine Learning with Graphs by Jure Leskovec: https://lnkd.in/gQran26Z
ğŸ”¹ CS234 - Reinforcement Learning by Emma Brunskill: https://lnkd.in/gwZKQ-28
ğŸ”¹ CS330 - Deep Multi-task and Meta Learning by Chelsea Finn: https://lnkd.in/gvVr_Y4M
ğŸ”¹ CS25 - Transformers United by Divyansh Garg, Steven Feng, and Rylan Schaeffer: https://lnkd.in/gEtKgHGC

ğŸ“š Carnegie Mellon University
ğŸ”¹ CS/LTI 11-711: Advanced NLP by Graham Neubig: https://lnkd.in/gSt29ZVt
ğŸ”¹ CS/LTI 11-747: Neural Networks for NLP by Graham Neubig: https://lnkd.in/gRRrY8uq
ğŸ”¹ CS/LTI 11-737: Multilingual NLP by Graham Neubig: https://lnkd.in/g8QkaTfy
ğŸ”¹ CS/LTI 11-777: Multimodal Machine Learning by Louis-Philippe Morency: https://lnkd.in/gKFJDbU4
ğŸ”¹ CS/LTI 11-785: Introduction to Deep Learning by Bhiksha Raj and Rita Singh:
https://lnkd.in/gVp96GdB
ğŸ”¹ CS/LTI Low Resource NLP Bootcamp 2020 by Graham Neubig: https://lnkd.in/grYqa3YZ

ğŸ“š Massachusetts Institute of Technology
ğŸ”¹ 6.S191 - Introduction to Deep Learning by Alexander Amini and Ava Amini: https://lnkd.in/gWMUpMQg
ğŸ”¹ 6.S094 - Deep Learning by Lex Fridman: https://lnkd.in/gcDgqbH6
ğŸ”¹ 6.S192 - Deep Learning for Art, Aesthetics, and Creativity by Ali Jahanian: https://lnkd.in/gEyRbEZx

ğŸ“š University College London (UCL)
ğŸ”¹ COMP M050 Reinforcement Learning by David Silver: https://lnkd.in/gEpkWmqh



MLOps is the DevOps for machine learning.

It streamlines the end-to-end machine learning lifecycle by integrating best practices from the software development world.

This ensures that machine learning models are not just built, but are also effectively deployed, monitored, and managed in production.

It includes:
1. Continuous Integration (CI): Automated testing of ML code and pipelines.
2. Continuous Delivery (CD): Automate model deployment processes.
3. Model Versioning: Track and manage different versions of models and data.
4. Model Monitoring: Keep an eye on model performance and health in real-time.
5. Model Retraining: Ensure models stay relevant by retraining them with new data.
6. Scalability & Serving: Efficiently serve models to handle real-world traffic.
7. Collaboration: Tools for team collaboration and reproducibility across ML workflows.

MLOps ensures reliable and faster delivery of high-quality ML models to production.
â†“
https://media.licdn.com/dms/image/D5622AQHv1d7ajrjPPg/feedshare-shrink_2048_1536/0/1691516134239?e=1694649600&v=beta&t=Gm7lgf7vQGff910pxXw75oYz84iTUzE4NlYZGWiqK0o 

Notebooks for finetuning and inference of Llama-2 and LLMs

- bnb-4bit-training-with-inference
https://lnkd.in/dtiky_k8

- Llama 2 Fine-Tuning using QLora
https://lnkd.in/dEd4xTAR

- Fine-tune Llama 2 in Google Colab
https://lnkd.in/dHi2JHcf

- llama-2-70b-chat-agent
https://lnkd.in/dWjSdqRB

- text-generation-inference
https://lnkd.in/dvmMGhD6

- text-generation-webui
https://lnkd.in/dQ_NVNkP

- llama2-webui
https://lnkd.in/dkY3c_Pc

- llama_cpu_interface
https://lnkd.in/dyq2ft-q


########
AI is taking over the world. And, you can either take a backseat. Or, invest your time in learning it. Here's my ğŸ±-ğ˜€ğ˜ğ—²ğ—½ ğ—³ğ—¼ğ—¿ğ—ºğ˜‚ğ—¹ğ—® ğŸ“š on how I gain deep intuition of ğ—¦ğ—¢ğ—§ğ—”ğ˜€ ğ—¹ğ—¶ğ—¸ğ—² ğ—¦ğ˜ğ—®ğ—¯ğ—¹ğ—² ğ——ğ—¶ğ—³ğ—³ğ˜‚ğ˜€ğ—¶ğ—¼ğ—» and ğ—Ÿğ—®ğ—¿ğ—´ğ—² ğ—Ÿğ—®ğ—»ğ—´ğ˜‚ğ—®ğ—´ğ—² ğ— ğ—¼ğ—±ğ—²ğ—¹ğ˜€ ğŸ‘‡

ğ—¦ğ˜ğ—²ğ—½ ğŸ­ - ğŸ’¡ ğ—šğ—®ğ˜ğ—µğ—²ğ—¿ ğ—œğ—»ğ—´ğ—¿ğ—²ğ—±ğ—¶ğ—²ğ—»ğ˜ğ˜€ ğ—¤ğ˜‚ğ—¶ğ—°ğ—¸ğ—¹ğ˜†

When you want to cook a dish, what's the first step? You have to know what ingredients to pick up.

To understand a SOTA model like Stable Diffusion, start by gathering the essential components that make up the algo.

- Forward Diffusion Process
- Variance Scheduling
- Markov Chain
- Reverse Diffusion Process
- UNet
- Parameter Sampling
- Attention Mechanism

Once you have your "ingredient", you now have a map of the building blocks you need to understand how the pieces fit together for the overall model process.

ğ—¦ğ˜ğ—²ğ—½ ğŸ® - âœï¸ ğ——ğ˜„ğ—²ğ—¹ğ—¹ ğ—¼ğ—» ğ˜ğ—µğ—² ğ—ºğ—®ğ˜ğ—µ

I can't emphasize this enough. Knowing how to apply the algorithm with a Tensorflow library is just the tip of the iceberg.

If you want a deep intuition of SOTA model, find a coffee shop and work out the math in matrix form step-by-step.

ğ—¦ğ˜ğ—²ğ—½ ğŸ¯ - âŒ¨ï¸ ğ—–ğ—¼ğ—±ğ—² ğ—¶ğ˜

Import tensorflow or import torch, and play around with the algorithm on a toy problem.

Browse Githubs, Medium, Kaggle, or Hugging Face for implementations.

Copy the code, play around with the parameter values, and input a new dataset and observe the output.

ğ—¦ğ˜ğ—²ğ—½ ğŸ° - âœ… ğ—–ğ—¼ğ—±ğ—² ğ—¶ğ˜ ğ—³ğ—¿ğ—¼ğ—º ğ˜€ğ—°ğ—¿ğ—®ğ˜ğ—°ğ—µ

Andrej Karpathy shares this a lot, and it's also something I've been doing since I became a practitioner in ML 7 years ago. And, it's what I've done for all the popular types of ML algos (e.g. XGBoost, RNN, Diffusion Models)

Code it from scratch - see how far you could go in each level.

Level 1 - Use tensorflow/torch
Level 2 - Only use numpy
Level 3 - Only use vanilla python

ğ—¦ğ˜ğ—²ğ—½ ğŸ± - ğŸ“ ğ—§ğ—²ğ—®ğ—°ğ—µ ğ—¶ğ˜

The best way to learn is to teach. Write about it. Talk about it. Share your learning with the world so others could learn.

(ğ—¦ğ˜ğ—²ğ—½ ğŸ²) - ğŸ¯ ğ—¥ğ—²ğ—½ğ—²ğ—®ğ˜ ğ—¶ğ˜ ğ—³ğ—¼ğ—¿ ğ˜ğ—µğ—² ğ—»ğ—²ğ˜…ğ˜ ğ—¦ğ—¢ğ—§ğ—”

Learning never stops. Continue to make progress in growing your knowledge in ML/AI.

ğŸ‘‰ What's the algo you are learning right now? Drop one below ğŸ‘‡
ğŸ‘‰ Land dream data job ğŸŒˆ on ğ——ğ—®ğ˜ğ—®ğ—œğ—»ğ˜ğ—²ğ—¿ğ˜ƒğ—¶ğ—²ğ˜„[.]ğ—°ğ—¼ğ—º ğŸš€
ğŸ‘‰ Found this post helpful? Smash ğŸ‘ and follow Daniel Lee ğŸ“š